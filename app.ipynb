{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor #n-dimensional matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.target_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data, batch_size = 100,\n",
    "        shuffle = True,\n",
    "        num_workers = 1\n",
    "    ),\n",
    "\n",
    "    'test': DataLoader(test_data, batch_size = 100,\n",
    "        shuffle = True,\n",
    "        num_workers = 1\n",
    "    ),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x1fedae67080>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x1fedae64aa0>}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} '\n",
    "                  f'({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} '\n",
    "          f'({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 1 [0/60000 (0%)]\tLoss: 1.555832\n",
      "Train epoch: 1 [2000/60000 (3%)]\tLoss: 1.525207\n",
      "Train epoch: 1 [4000/60000 (7%)]\tLoss: 1.513704\n",
      "Train epoch: 1 [6000/60000 (10%)]\tLoss: 1.499063\n",
      "Train epoch: 1 [8000/60000 (13%)]\tLoss: 1.544226\n",
      "Train epoch: 1 [10000/60000 (17%)]\tLoss: 1.606310\n",
      "Train epoch: 1 [12000/60000 (20%)]\tLoss: 1.543165\n",
      "Train epoch: 1 [14000/60000 (23%)]\tLoss: 1.522582\n",
      "Train epoch: 1 [16000/60000 (27%)]\tLoss: 1.544700\n",
      "Train epoch: 1 [18000/60000 (30%)]\tLoss: 1.476290\n",
      "Train epoch: 1 [20000/60000 (33%)]\tLoss: 1.511573\n",
      "Train epoch: 1 [22000/60000 (37%)]\tLoss: 1.489369\n",
      "Train epoch: 1 [24000/60000 (40%)]\tLoss: 1.505647\n",
      "Train epoch: 1 [26000/60000 (43%)]\tLoss: 1.533874\n",
      "Train epoch: 1 [28000/60000 (47%)]\tLoss: 1.526429\n",
      "Train epoch: 1 [30000/60000 (50%)]\tLoss: 1.560058\n",
      "Train epoch: 1 [32000/60000 (53%)]\tLoss: 1.543466\n",
      "Train epoch: 1 [34000/60000 (57%)]\tLoss: 1.516959\n",
      "Train epoch: 1 [36000/60000 (60%)]\tLoss: 1.480167\n",
      "Train epoch: 1 [38000/60000 (63%)]\tLoss: 1.495869\n",
      "Train epoch: 1 [40000/60000 (67%)]\tLoss: 1.501078\n",
      "Train epoch: 1 [42000/60000 (70%)]\tLoss: 1.528869\n",
      "Train epoch: 1 [44000/60000 (73%)]\tLoss: 1.553696\n",
      "Train epoch: 1 [46000/60000 (77%)]\tLoss: 1.538793\n",
      "Train epoch: 1 [48000/60000 (80%)]\tLoss: 1.538941\n",
      "Train epoch: 1 [50000/60000 (83%)]\tLoss: 1.527955\n",
      "Train epoch: 1 [52000/60000 (87%)]\tLoss: 1.509508\n",
      "Train epoch: 1 [54000/60000 (90%)]\tLoss: 1.529859\n",
      "Train epoch: 1 [56000/60000 (93%)]\tLoss: 1.487272\n",
      "Train epoch: 1 [58000/60000 (97%)]\tLoss: 1.506207\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9731/10000 (97%)\n",
      "\n",
      "Train epoch: 2 [0/60000 (0%)]\tLoss: 1.533060\n",
      "Train epoch: 2 [2000/60000 (3%)]\tLoss: 1.540965\n",
      "Train epoch: 2 [4000/60000 (7%)]\tLoss: 1.503887\n",
      "Train epoch: 2 [6000/60000 (10%)]\tLoss: 1.521162\n",
      "Train epoch: 2 [8000/60000 (13%)]\tLoss: 1.514016\n",
      "Train epoch: 2 [10000/60000 (17%)]\tLoss: 1.522869\n",
      "Train epoch: 2 [12000/60000 (20%)]\tLoss: 1.489456\n",
      "Train epoch: 2 [14000/60000 (23%)]\tLoss: 1.552224\n",
      "Train epoch: 2 [16000/60000 (27%)]\tLoss: 1.534116\n",
      "Train epoch: 2 [18000/60000 (30%)]\tLoss: 1.516287\n",
      "Train epoch: 2 [20000/60000 (33%)]\tLoss: 1.478308\n",
      "Train epoch: 2 [22000/60000 (37%)]\tLoss: 1.510805\n",
      "Train epoch: 2 [24000/60000 (40%)]\tLoss: 1.519590\n",
      "Train epoch: 2 [26000/60000 (43%)]\tLoss: 1.567964\n",
      "Train epoch: 2 [28000/60000 (47%)]\tLoss: 1.551898\n",
      "Train epoch: 2 [30000/60000 (50%)]\tLoss: 1.513954\n",
      "Train epoch: 2 [32000/60000 (53%)]\tLoss: 1.516385\n",
      "Train epoch: 2 [34000/60000 (57%)]\tLoss: 1.509028\n",
      "Train epoch: 2 [36000/60000 (60%)]\tLoss: 1.535567\n",
      "Train epoch: 2 [38000/60000 (63%)]\tLoss: 1.484770\n",
      "Train epoch: 2 [40000/60000 (67%)]\tLoss: 1.504613\n",
      "Train epoch: 2 [42000/60000 (70%)]\tLoss: 1.500312\n",
      "Train epoch: 2 [44000/60000 (73%)]\tLoss: 1.527105\n",
      "Train epoch: 2 [46000/60000 (77%)]\tLoss: 1.535709\n",
      "Train epoch: 2 [48000/60000 (80%)]\tLoss: 1.559499\n",
      "Train epoch: 2 [50000/60000 (83%)]\tLoss: 1.497915\n",
      "Train epoch: 2 [52000/60000 (87%)]\tLoss: 1.492485\n",
      "Train epoch: 2 [54000/60000 (90%)]\tLoss: 1.549139\n",
      "Train epoch: 2 [56000/60000 (93%)]\tLoss: 1.540380\n",
      "Train epoch: 2 [58000/60000 (97%)]\tLoss: 1.499429\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9744/10000 (97%)\n",
      "\n",
      "Train epoch: 3 [0/60000 (0%)]\tLoss: 1.521426\n",
      "Train epoch: 3 [2000/60000 (3%)]\tLoss: 1.552341\n",
      "Train epoch: 3 [4000/60000 (7%)]\tLoss: 1.520608\n",
      "Train epoch: 3 [6000/60000 (10%)]\tLoss: 1.496104\n",
      "Train epoch: 3 [8000/60000 (13%)]\tLoss: 1.558566\n",
      "Train epoch: 3 [10000/60000 (17%)]\tLoss: 1.481404\n",
      "Train epoch: 3 [12000/60000 (20%)]\tLoss: 1.545780\n",
      "Train epoch: 3 [14000/60000 (23%)]\tLoss: 1.521178\n",
      "Train epoch: 3 [16000/60000 (27%)]\tLoss: 1.550125\n",
      "Train epoch: 3 [18000/60000 (30%)]\tLoss: 1.494374\n",
      "Train epoch: 3 [20000/60000 (33%)]\tLoss: 1.516970\n",
      "Train epoch: 3 [22000/60000 (37%)]\tLoss: 1.560842\n",
      "Train epoch: 3 [24000/60000 (40%)]\tLoss: 1.576329\n",
      "Train epoch: 3 [26000/60000 (43%)]\tLoss: 1.499303\n",
      "Train epoch: 3 [28000/60000 (47%)]\tLoss: 1.541415\n",
      "Train epoch: 3 [30000/60000 (50%)]\tLoss: 1.538343\n",
      "Train epoch: 3 [32000/60000 (53%)]\tLoss: 1.565474\n",
      "Train epoch: 3 [34000/60000 (57%)]\tLoss: 1.531338\n",
      "Train epoch: 3 [36000/60000 (60%)]\tLoss: 1.497669\n",
      "Train epoch: 3 [38000/60000 (63%)]\tLoss: 1.525405\n",
      "Train epoch: 3 [40000/60000 (67%)]\tLoss: 1.533527\n",
      "Train epoch: 3 [42000/60000 (70%)]\tLoss: 1.568129\n",
      "Train epoch: 3 [44000/60000 (73%)]\tLoss: 1.565390\n",
      "Train epoch: 3 [46000/60000 (77%)]\tLoss: 1.533497\n",
      "Train epoch: 3 [48000/60000 (80%)]\tLoss: 1.503496\n",
      "Train epoch: 3 [50000/60000 (83%)]\tLoss: 1.506826\n",
      "Train epoch: 3 [52000/60000 (87%)]\tLoss: 1.490853\n",
      "Train epoch: 3 [54000/60000 (90%)]\tLoss: 1.516139\n",
      "Train epoch: 3 [56000/60000 (93%)]\tLoss: 1.525613\n",
      "Train epoch: 3 [58000/60000 (97%)]\tLoss: 1.555052\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9750/10000 (98%)\n",
      "\n",
      "Train epoch: 4 [0/60000 (0%)]\tLoss: 1.517305\n",
      "Train epoch: 4 [2000/60000 (3%)]\tLoss: 1.544619\n",
      "Train epoch: 4 [4000/60000 (7%)]\tLoss: 1.494636\n",
      "Train epoch: 4 [6000/60000 (10%)]\tLoss: 1.546672\n",
      "Train epoch: 4 [8000/60000 (13%)]\tLoss: 1.545974\n",
      "Train epoch: 4 [10000/60000 (17%)]\tLoss: 1.512632\n",
      "Train epoch: 4 [12000/60000 (20%)]\tLoss: 1.532630\n",
      "Train epoch: 4 [14000/60000 (23%)]\tLoss: 1.514458\n",
      "Train epoch: 4 [16000/60000 (27%)]\tLoss: 1.530028\n",
      "Train epoch: 4 [18000/60000 (30%)]\tLoss: 1.551882\n",
      "Train epoch: 4 [20000/60000 (33%)]\tLoss: 1.506759\n",
      "Train epoch: 4 [22000/60000 (37%)]\tLoss: 1.501405\n",
      "Train epoch: 4 [24000/60000 (40%)]\tLoss: 1.564768\n",
      "Train epoch: 4 [26000/60000 (43%)]\tLoss: 1.485489\n",
      "Train epoch: 4 [28000/60000 (47%)]\tLoss: 1.528330\n",
      "Train epoch: 4 [30000/60000 (50%)]\tLoss: 1.519933\n",
      "Train epoch: 4 [32000/60000 (53%)]\tLoss: 1.538561\n",
      "Train epoch: 4 [34000/60000 (57%)]\tLoss: 1.511238\n",
      "Train epoch: 4 [36000/60000 (60%)]\tLoss: 1.530840\n",
      "Train epoch: 4 [38000/60000 (63%)]\tLoss: 1.526790\n",
      "Train epoch: 4 [40000/60000 (67%)]\tLoss: 1.519386\n",
      "Train epoch: 4 [42000/60000 (70%)]\tLoss: 1.532103\n",
      "Train epoch: 4 [44000/60000 (73%)]\tLoss: 1.493224\n",
      "Train epoch: 4 [46000/60000 (77%)]\tLoss: 1.505093\n",
      "Train epoch: 4 [48000/60000 (80%)]\tLoss: 1.535799\n",
      "Train epoch: 4 [50000/60000 (83%)]\tLoss: 1.528647\n",
      "Train epoch: 4 [52000/60000 (87%)]\tLoss: 1.515061\n",
      "Train epoch: 4 [54000/60000 (90%)]\tLoss: 1.519585\n",
      "Train epoch: 4 [56000/60000 (93%)]\tLoss: 1.541940\n",
      "Train epoch: 4 [58000/60000 (97%)]\tLoss: 1.506324\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9748/10000 (97%)\n",
      "\n",
      "Train epoch: 5 [0/60000 (0%)]\tLoss: 1.498794\n",
      "Train epoch: 5 [2000/60000 (3%)]\tLoss: 1.557675\n",
      "Train epoch: 5 [4000/60000 (7%)]\tLoss: 1.550611\n",
      "Train epoch: 5 [6000/60000 (10%)]\tLoss: 1.502185\n",
      "Train epoch: 5 [8000/60000 (13%)]\tLoss: 1.513516\n",
      "Train epoch: 5 [10000/60000 (17%)]\tLoss: 1.512888\n",
      "Train epoch: 5 [12000/60000 (20%)]\tLoss: 1.521272\n",
      "Train epoch: 5 [14000/60000 (23%)]\tLoss: 1.557403\n",
      "Train epoch: 5 [16000/60000 (27%)]\tLoss: 1.533442\n",
      "Train epoch: 5 [18000/60000 (30%)]\tLoss: 1.500714\n",
      "Train epoch: 5 [20000/60000 (33%)]\tLoss: 1.500524\n",
      "Train epoch: 5 [22000/60000 (37%)]\tLoss: 1.500344\n",
      "Train epoch: 5 [24000/60000 (40%)]\tLoss: 1.503489\n",
      "Train epoch: 5 [26000/60000 (43%)]\tLoss: 1.504562\n",
      "Train epoch: 5 [28000/60000 (47%)]\tLoss: 1.520878\n",
      "Train epoch: 5 [30000/60000 (50%)]\tLoss: 1.519402\n",
      "Train epoch: 5 [32000/60000 (53%)]\tLoss: 1.548172\n",
      "Train epoch: 5 [34000/60000 (57%)]\tLoss: 1.498886\n",
      "Train epoch: 5 [36000/60000 (60%)]\tLoss: 1.523896\n",
      "Train epoch: 5 [38000/60000 (63%)]\tLoss: 1.534901\n",
      "Train epoch: 5 [40000/60000 (67%)]\tLoss: 1.497429\n",
      "Train epoch: 5 [42000/60000 (70%)]\tLoss: 1.501852\n",
      "Train epoch: 5 [44000/60000 (73%)]\tLoss: 1.540080\n",
      "Train epoch: 5 [46000/60000 (77%)]\tLoss: 1.528313\n",
      "Train epoch: 5 [48000/60000 (80%)]\tLoss: 1.523603\n",
      "Train epoch: 5 [50000/60000 (83%)]\tLoss: 1.576916\n",
      "Train epoch: 5 [52000/60000 (87%)]\tLoss: 1.501145\n",
      "Train epoch: 5 [54000/60000 (90%)]\tLoss: 1.512333\n",
      "Train epoch: 5 [56000/60000 (93%)]\tLoss: 1.568331\n",
      "Train epoch: 5 [58000/60000 (97%)]\tLoss: 1.503513\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9769/10000 (98%)\n",
      "\n",
      "Train epoch: 6 [0/60000 (0%)]\tLoss: 1.511660\n",
      "Train epoch: 6 [2000/60000 (3%)]\tLoss: 1.519430\n",
      "Train epoch: 6 [4000/60000 (7%)]\tLoss: 1.518060\n",
      "Train epoch: 6 [6000/60000 (10%)]\tLoss: 1.503737\n",
      "Train epoch: 6 [8000/60000 (13%)]\tLoss: 1.491566\n",
      "Train epoch: 6 [10000/60000 (17%)]\tLoss: 1.515728\n",
      "Train epoch: 6 [12000/60000 (20%)]\tLoss: 1.501356\n",
      "Train epoch: 6 [14000/60000 (23%)]\tLoss: 1.516146\n",
      "Train epoch: 6 [16000/60000 (27%)]\tLoss: 1.559863\n",
      "Train epoch: 6 [18000/60000 (30%)]\tLoss: 1.518316\n",
      "Train epoch: 6 [20000/60000 (33%)]\tLoss: 1.522767\n",
      "Train epoch: 6 [22000/60000 (37%)]\tLoss: 1.510774\n",
      "Train epoch: 6 [24000/60000 (40%)]\tLoss: 1.503886\n",
      "Train epoch: 6 [26000/60000 (43%)]\tLoss: 1.509115\n",
      "Train epoch: 6 [28000/60000 (47%)]\tLoss: 1.524348\n",
      "Train epoch: 6 [30000/60000 (50%)]\tLoss: 1.519717\n",
      "Train epoch: 6 [32000/60000 (53%)]\tLoss: 1.504830\n",
      "Train epoch: 6 [34000/60000 (57%)]\tLoss: 1.503921\n",
      "Train epoch: 6 [36000/60000 (60%)]\tLoss: 1.512878\n",
      "Train epoch: 6 [38000/60000 (63%)]\tLoss: 1.487606\n",
      "Train epoch: 6 [40000/60000 (67%)]\tLoss: 1.521937\n",
      "Train epoch: 6 [42000/60000 (70%)]\tLoss: 1.509570\n",
      "Train epoch: 6 [44000/60000 (73%)]\tLoss: 1.570056\n",
      "Train epoch: 6 [46000/60000 (77%)]\tLoss: 1.502382\n",
      "Train epoch: 6 [48000/60000 (80%)]\tLoss: 1.534060\n",
      "Train epoch: 6 [50000/60000 (83%)]\tLoss: 1.537942\n",
      "Train epoch: 6 [52000/60000 (87%)]\tLoss: 1.485421\n",
      "Train epoch: 6 [54000/60000 (90%)]\tLoss: 1.512229\n",
      "Train epoch: 6 [56000/60000 (93%)]\tLoss: 1.551041\n",
      "Train epoch: 6 [58000/60000 (97%)]\tLoss: 1.508207\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9759/10000 (98%)\n",
      "\n",
      "Train epoch: 7 [0/60000 (0%)]\tLoss: 1.494330\n",
      "Train epoch: 7 [2000/60000 (3%)]\tLoss: 1.524612\n",
      "Train epoch: 7 [4000/60000 (7%)]\tLoss: 1.509637\n",
      "Train epoch: 7 [6000/60000 (10%)]\tLoss: 1.510085\n",
      "Train epoch: 7 [8000/60000 (13%)]\tLoss: 1.509251\n",
      "Train epoch: 7 [10000/60000 (17%)]\tLoss: 1.532838\n",
      "Train epoch: 7 [12000/60000 (20%)]\tLoss: 1.498620\n",
      "Train epoch: 7 [14000/60000 (23%)]\tLoss: 1.536535\n",
      "Train epoch: 7 [16000/60000 (27%)]\tLoss: 1.526602\n",
      "Train epoch: 7 [18000/60000 (30%)]\tLoss: 1.488718\n",
      "Train epoch: 7 [20000/60000 (33%)]\tLoss: 1.504659\n",
      "Train epoch: 7 [22000/60000 (37%)]\tLoss: 1.526119\n",
      "Train epoch: 7 [24000/60000 (40%)]\tLoss: 1.501187\n",
      "Train epoch: 7 [26000/60000 (43%)]\tLoss: 1.553530\n",
      "Train epoch: 7 [28000/60000 (47%)]\tLoss: 1.472191\n",
      "Train epoch: 7 [30000/60000 (50%)]\tLoss: 1.525904\n",
      "Train epoch: 7 [32000/60000 (53%)]\tLoss: 1.562143\n",
      "Train epoch: 7 [34000/60000 (57%)]\tLoss: 1.524973\n",
      "Train epoch: 7 [36000/60000 (60%)]\tLoss: 1.504342\n",
      "Train epoch: 7 [38000/60000 (63%)]\tLoss: 1.522563\n",
      "Train epoch: 7 [40000/60000 (67%)]\tLoss: 1.563933\n",
      "Train epoch: 7 [42000/60000 (70%)]\tLoss: 1.506387\n",
      "Train epoch: 7 [44000/60000 (73%)]\tLoss: 1.528188\n",
      "Train epoch: 7 [46000/60000 (77%)]\tLoss: 1.542871\n",
      "Train epoch: 7 [48000/60000 (80%)]\tLoss: 1.507113\n",
      "Train epoch: 7 [50000/60000 (83%)]\tLoss: 1.513749\n",
      "Train epoch: 7 [52000/60000 (87%)]\tLoss: 1.515234\n",
      "Train epoch: 7 [54000/60000 (90%)]\tLoss: 1.521858\n",
      "Train epoch: 7 [56000/60000 (93%)]\tLoss: 1.517041\n",
      "Train epoch: 7 [58000/60000 (97%)]\tLoss: 1.506239\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9791/10000 (98%)\n",
      "\n",
      "Train epoch: 8 [0/60000 (0%)]\tLoss: 1.495470\n",
      "Train epoch: 8 [2000/60000 (3%)]\tLoss: 1.513289\n",
      "Train epoch: 8 [4000/60000 (7%)]\tLoss: 1.474947\n",
      "Train epoch: 8 [6000/60000 (10%)]\tLoss: 1.485821\n",
      "Train epoch: 8 [8000/60000 (13%)]\tLoss: 1.531151\n",
      "Train epoch: 8 [10000/60000 (17%)]\tLoss: 1.530558\n",
      "Train epoch: 8 [12000/60000 (20%)]\tLoss: 1.523019\n",
      "Train epoch: 8 [14000/60000 (23%)]\tLoss: 1.513086\n",
      "Train epoch: 8 [16000/60000 (27%)]\tLoss: 1.534976\n",
      "Train epoch: 8 [18000/60000 (30%)]\tLoss: 1.534709\n",
      "Train epoch: 8 [20000/60000 (33%)]\tLoss: 1.500837\n",
      "Train epoch: 8 [22000/60000 (37%)]\tLoss: 1.506019\n",
      "Train epoch: 8 [24000/60000 (40%)]\tLoss: 1.529765\n",
      "Train epoch: 8 [26000/60000 (43%)]\tLoss: 1.539725\n",
      "Train epoch: 8 [28000/60000 (47%)]\tLoss: 1.545994\n",
      "Train epoch: 8 [30000/60000 (50%)]\tLoss: 1.539442\n",
      "Train epoch: 8 [32000/60000 (53%)]\tLoss: 1.480882\n",
      "Train epoch: 8 [34000/60000 (57%)]\tLoss: 1.523601\n",
      "Train epoch: 8 [36000/60000 (60%)]\tLoss: 1.501827\n",
      "Train epoch: 8 [38000/60000 (63%)]\tLoss: 1.508479\n",
      "Train epoch: 8 [40000/60000 (67%)]\tLoss: 1.539570\n",
      "Train epoch: 8 [42000/60000 (70%)]\tLoss: 1.535716\n",
      "Train epoch: 8 [44000/60000 (73%)]\tLoss: 1.524871\n",
      "Train epoch: 8 [46000/60000 (77%)]\tLoss: 1.490973\n",
      "Train epoch: 8 [48000/60000 (80%)]\tLoss: 1.550077\n",
      "Train epoch: 8 [50000/60000 (83%)]\tLoss: 1.548344\n",
      "Train epoch: 8 [52000/60000 (87%)]\tLoss: 1.580377\n",
      "Train epoch: 8 [54000/60000 (90%)]\tLoss: 1.532261\n",
      "Train epoch: 8 [56000/60000 (93%)]\tLoss: 1.538537\n",
      "Train epoch: 8 [58000/60000 (97%)]\tLoss: 1.512065\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9773/10000 (98%)\n",
      "\n",
      "Train epoch: 9 [0/60000 (0%)]\tLoss: 1.587043\n",
      "Train epoch: 9 [2000/60000 (3%)]\tLoss: 1.500863\n",
      "Train epoch: 9 [4000/60000 (7%)]\tLoss: 1.511255\n",
      "Train epoch: 9 [6000/60000 (10%)]\tLoss: 1.481801\n",
      "Train epoch: 9 [8000/60000 (13%)]\tLoss: 1.489749\n",
      "Train epoch: 9 [10000/60000 (17%)]\tLoss: 1.506697\n",
      "Train epoch: 9 [12000/60000 (20%)]\tLoss: 1.516514\n",
      "Train epoch: 9 [14000/60000 (23%)]\tLoss: 1.544650\n",
      "Train epoch: 9 [16000/60000 (27%)]\tLoss: 1.528890\n",
      "Train epoch: 9 [18000/60000 (30%)]\tLoss: 1.513029\n",
      "Train epoch: 9 [20000/60000 (33%)]\tLoss: 1.506747\n",
      "Train epoch: 9 [22000/60000 (37%)]\tLoss: 1.526256\n",
      "Train epoch: 9 [24000/60000 (40%)]\tLoss: 1.518241\n",
      "Train epoch: 9 [26000/60000 (43%)]\tLoss: 1.473847\n",
      "Train epoch: 9 [28000/60000 (47%)]\tLoss: 1.491528\n",
      "Train epoch: 9 [30000/60000 (50%)]\tLoss: 1.523729\n",
      "Train epoch: 9 [32000/60000 (53%)]\tLoss: 1.530998\n",
      "Train epoch: 9 [34000/60000 (57%)]\tLoss: 1.540239\n",
      "Train epoch: 9 [36000/60000 (60%)]\tLoss: 1.504361\n",
      "Train epoch: 9 [38000/60000 (63%)]\tLoss: 1.501527\n",
      "Train epoch: 9 [40000/60000 (67%)]\tLoss: 1.487519\n",
      "Train epoch: 9 [42000/60000 (70%)]\tLoss: 1.511472\n",
      "Train epoch: 9 [44000/60000 (73%)]\tLoss: 1.495327\n",
      "Train epoch: 9 [46000/60000 (77%)]\tLoss: 1.547965\n",
      "Train epoch: 9 [48000/60000 (80%)]\tLoss: 1.492199\n",
      "Train epoch: 9 [50000/60000 (83%)]\tLoss: 1.521992\n",
      "Train epoch: 9 [52000/60000 (87%)]\tLoss: 1.497815\n",
      "Train epoch: 9 [54000/60000 (90%)]\tLoss: 1.510699\n",
      "Train epoch: 9 [56000/60000 (93%)]\tLoss: 1.512402\n",
      "Train epoch: 9 [58000/60000 (97%)]\tLoss: 1.548977\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9790/10000 (98%)\n",
      "\n",
      "Train epoch: 10 [0/60000 (0%)]\tLoss: 1.535543\n",
      "Train epoch: 10 [2000/60000 (3%)]\tLoss: 1.511666\n",
      "Train epoch: 10 [4000/60000 (7%)]\tLoss: 1.511907\n",
      "Train epoch: 10 [6000/60000 (10%)]\tLoss: 1.492668\n",
      "Train epoch: 10 [8000/60000 (13%)]\tLoss: 1.521630\n",
      "Train epoch: 10 [10000/60000 (17%)]\tLoss: 1.491301\n",
      "Train epoch: 10 [12000/60000 (20%)]\tLoss: 1.520742\n",
      "Train epoch: 10 [14000/60000 (23%)]\tLoss: 1.504878\n",
      "Train epoch: 10 [16000/60000 (27%)]\tLoss: 1.489926\n",
      "Train epoch: 10 [18000/60000 (30%)]\tLoss: 1.525283\n",
      "Train epoch: 10 [20000/60000 (33%)]\tLoss: 1.511745\n",
      "Train epoch: 10 [22000/60000 (37%)]\tLoss: 1.522964\n",
      "Train epoch: 10 [24000/60000 (40%)]\tLoss: 1.525998\n",
      "Train epoch: 10 [26000/60000 (43%)]\tLoss: 1.530626\n",
      "Train epoch: 10 [28000/60000 (47%)]\tLoss: 1.512665\n",
      "Train epoch: 10 [30000/60000 (50%)]\tLoss: 1.533408\n",
      "Train epoch: 10 [32000/60000 (53%)]\tLoss: 1.552289\n",
      "Train epoch: 10 [34000/60000 (57%)]\tLoss: 1.513265\n",
      "Train epoch: 10 [36000/60000 (60%)]\tLoss: 1.514360\n",
      "Train epoch: 10 [38000/60000 (63%)]\tLoss: 1.505145\n",
      "Train epoch: 10 [40000/60000 (67%)]\tLoss: 1.508033\n",
      "Train epoch: 10 [42000/60000 (70%)]\tLoss: 1.507089\n",
      "Train epoch: 10 [44000/60000 (73%)]\tLoss: 1.515631\n",
      "Train epoch: 10 [46000/60000 (77%)]\tLoss: 1.481437\n",
      "Train epoch: 10 [48000/60000 (80%)]\tLoss: 1.482856\n",
      "Train epoch: 10 [50000/60000 (83%)]\tLoss: 1.554397\n",
      "Train epoch: 10 [52000/60000 (87%)]\tLoss: 1.527489\n",
      "Train epoch: 10 [54000/60000 (90%)]\tLoss: 1.537635\n",
      "Train epoch: 10 [56000/60000 (93%)]\tLoss: 1.507919\n",
      "Train epoch: 10 [58000/60000 (97%)]\tLoss: 1.512742\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9797/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "data, target = test_data[0]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "print(f'Prediction: {prediction}')\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
